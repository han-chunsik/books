---
title: 2025 챌린지 - 매일 기술 면접 답변하기
author: 한춘식
date: 2025-04-09
category: books
layout: post
toc:
    enabled: true
---  

# 2025.04.16
## 시스템 장애 발생 시 신속하게 대응하고 복구하기 위해 어떤 전략을 수립하고 적용했는지 구체적으로 설명해 주세요.
> 카테고리: Backend, 장애 대응 및 복구 전략

> 힌트: 장애 탐지, 알림 시스템, 롤백 전략, 재시도 메커니즘 등의 구체적인 대응 방식을 중심으로 설명해 주세요.

### 답변
사내 GitLab에서 장애가 발생하면 개발 진행에 큰 영향을 주기 때문에, 이를 대비해 서버의 리소스 사용량과 서비스 상태를 실시간으로 확인할 수 있는 모니터링 시스템을 구축했습니다. 또한, 장애 발생 시 사내 메신저로 자동 알림이 전송되도록 구성하여, 신속한 인지와 대응이 가능하도록 했습니다.  
  
복구 전략 측면에서는, 만약의 사태에 대비해 외장 하드 디스크 두 개를 활용한 주간 백업 체계를 운영했습니다. 매주 GitLab 데이터를 외부 하드에 물리적으로 복사하여 저장하고,  매주 GitLab 데이터를 두 개의 하드 디스크에 번갈아 가며 백업하여, 하나의 디스크에 문제가 생겨도 다른 디스크에서 데이터를 복구할 수 있도록 했습니다. 이 방식은 백업 손실 가능성을 최소화하고, 실제 장애 상황에서도 신속하게 복구할 수 있도록 했습니다.  

> ##### 모범 답안
> 어쩌구
{: .block-tip } 

## 코드 리뷰와 테스트 자동화를 도입하거나 개선하여 개발 흐름이나 품질에 기여한 경험이 있다면 구체적으로 공유해 주세요.
> 카테고리: 공통, 코드 리뷰와 테스트 자동화

> 힌트: 도입 계기, 팀원과의 협업 방식, 퀄리티 향상 등의 구체적 변화가 드러나야 좋은 답변이 됩니다. (예: PR 템플릿, 리뷰 기준 정립, 테스트 커버리지 도입, 린트 자동화 등)

### 답변
기존에 수동으로 진행하던 UI 테스트 과정을 Selenium을 활용해 자동화한 경험이 있습니다. 주요 기능에 대한 테스트 시나리오를 작성하고, 코드 변경 사항이 기존 서비스에 영향을 주는지 자동으로 검증할 수 있도록 구성했습니다. 이를 통해 QA 시간을 단축할 수 있었고, 릴리스 전 품질 검증을 체계화할 수 있었으며, 배포 후 장애 발생률도 낮출 수 있었습니다.

> ##### 모범 답안
> 어쩌구
{: .block-tip } 

## 개발을 제외하고, 요즘 본인이 가장 중요하게 생각하거나 고민하고 있는 주제가 있다면 무엇인지 공유해 주세요.
> 카테고리: 인성, 개발 외의 관심사

> 힌트: 기술적인 이야기에서 잠시 벗어나, 지원자의 사고방식, 가치관, 현재의 관심사를 묻는 질문입니다. 꼭 멋진 답이 아니어도 좋습니다. 다만 '왜 그걸 중요하게 생각하는지'가 드러나는 게 핵심입니다.

### 답변  
요즘 가장 관심 있는 주제는 생각과 감정을 글로 표현하는 연습 입니다. 짧은 영상 콘텐츠에 자주 노출되다 보니 스스로 말하고자하는 바를 정확한 단어로 표현하는 것에 어려움을 느꼈습니다. 말도 그렇지만 글로 쓰는것도 마찬가지였습니다. 그래서 최근에는 짧은 글을 필사하는 책을 구매해서, 그 안의 단어나 문장을 참고해 제 감정이나 생각을 짧게 써보는 습관을 들이고 있습니다. 매일 글을 쓰면서 내면을 명확히 들여다보고 표현하는데 큰 도움이 되고 있습니다.

> ##### 모범 답안
> 어쩌구
{: .block-tip } 

---

<br>
<br>
<br>

# 2025.04.15
## API를 설계하거나 운영하면서, 일관성을 유지하고 변경을 관리하기 위해 어떤 전략을 사용했는지 설명해 주세요. (버전 관리, 응답 포맷 설계, 호환성 유지 방식 등을 중심으로)
> 카테고리: Backend, API 설계와 버전 관리 전략

> 힌트: 실무에서는 API가 한 번 공개되면 쉽게 바꿀 수 없습니다. 이 질문은 "처음부터 바뀔 수 있음을 고려하고 설계했는가"를 묻는 것입니다. URI 버전 관리, 응답 포맷 고정, Deprecation 정책 같은 구체적인 조치가 있다면 강력한 답변이 됩니다.

### 답변
사이드 프로젝트를 진행할 때, API의 변경 가능성과 일관성을 고려해 여러 전략을 적용했습니다. URI에 버전을 명시하여 호환성을 유지하고 기능을 확장할 수 있도록 했으며, 요청과 응답 포맷을 VO로 정의해 필드 구조 변경 시 영향을 최소화했습니다. 응답 포맷은 status, message, data 필드를 포함한 공통 포맷으로 설계했고, 예외 응답도 동일한 구조로 유지했습니다. 또한, Swagger를 활용해 API 문서를 자동화하여 팀원과 외부 사용자가 현재 사용 가능한 API를 쉽게 확인할 수 있도록 했습니다.


> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> 처음엔 기능만 되면 된다고 생각했는데, 프론트엔드 파트너가 다른 화면에서 재사용할 수 없다고 불편을 느끼는 걸 보고 설계가 중요하다는 걸 느꼈습니다.  
> 그 후에는 URI와 응답 포맷을 명확히 정의하고, 응답에 항상 status, message, data 필드를 고정해서 주도록 구조를 정리했습니다.  
> 추후에 기능이 추가될 때도 혼란 없이 API를 재사용할 수 있었고, 의도하지 않은 깨짐도 줄어들었습니다.  
>   
> [현직 개발자로, 이직 면접이라면?]  
> API 응답 포맷이 일관되지 않아 프론트와의 협업 효율이 떨어지는 문제가 반복됐습니다.  
> 이에 응답 구조를 JSON Schema 기반으로 명세화하고, Swagger 문서화와 함께 Lint를 통한 API 규칙 검사를 도입했습니다.  
> 또한 v1/v2로 URI 버전 관리 체계를 적용하고, Deprecation 시점과 호환 유지 기준을 문서로 정리해 신규 기능 도입 시 혼란을 최소화할 수 있었습니다.  
{: .block-tip } 

## 시스템이나 서비스 설계 시 데이터 보안 또는 개인정보 보호를 고려한 사례가 있다면, 어떤 원칙에 따라 설계했는지 설명해 주세요.
> 카테고리: 공통, 데이터 보안 설계

> 힌트: 개인정보 암호화나 마스킹은 기술 이름보다, 왜 그렇게 설계했는지를 중심으로 설명해 보세요. 최소 권한 원칙, 접근 통제, 로깅 등 보안 설계의 관점이 담기면 강한 인상을 줄 수 있습니다.

### 답변
비밀번호나 API 키와 같은 정보는 ConfigMap이 아닌 Secret에 저장하고, etcd에 저장될 때 암호화되도록 Kubernetes에서 제공하는 EncryptionConfiguration을 적용해 보안을 강화했습니다. 또한 Kubernetes API를 사용하는 경우, 최소 권한 원칙(PoLP)에 따라 서비스 계정에 필요한 권한만 부여하도록 RBAC 정책을 적용했습니다.

> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> 학생 대상 설문 시스템을 만들면서, 이름과 이메일을 그대로 저장한 것이 개인정보 노출 위험이 크다는 피드백을 받았습니다.  
> 이후 이메일은 일부 마스킹 처리, 이름은 해시함수를 적용하여 저장 방식 자체를 바꿨습니다.  
> 처음엔 단순 저장만 고려했는데, 데이터 설계 자체에 보안 개념이 들어가야 함을 느꼈습니다.  
>   
> [현직 개발자로, 이직 면접이라면?]  
> 회원 가입 및 주문 시스템 설계 시, 민감 데이터는 AES256으로 암호화하고, DB에는 접근 로깅을 남기도록 설정했습니다.  
> 또한 운영자 화면에서는 실명·연락처 정보를 마스킹 처리해 조회하도록 구성했고, 특정 권한 그룹에서만 접근 가능하도록 RBAC 기반 권한 제어를 적용했습니다.  
> 이후 개인정보보호 점검에서도 무이슈 통과 경험이 있습니다.  

## 업무나 프로젝트에서 높은 스트레스를 받았던 상황에서, 본인은 어떻게 동기를 유지하고 팀 사기를 관리했는지 경험을 공유해 주세요.
> 카테고리: 인성, 스트레스 관리 및 동기 부여

> 힌트: 이 질문은 지원자가 힘들었던 상황이 궁금한 게 아니라, 그 상황에서 어떤 태도나 루틴으로 회복했는지를 보고자 합니다. 개인 회고, 동료 격려, 팀 분위기 전환 등 구체적인 실천 방식이 있으면 좋습니다.

### 답변  
저는 스스로 세운 목표를 달성하지 못했을 때 스트레스를 받는 편입니다. 이러한 스트레스를 줄이기 위해 목표를 구체적으로 세분화하고, 매일 감정을 짧게 기록하며 스스로를 돌아보는 습관을 갖고 있습니다.  
업무 중 스트레스를 느낄 땐 잠깐 산책을 하거나 귀여운 것(새)을 보며 리프레시 하곤 합니다.  
팀 전체가 스트레스를 받을 땐 가능한 업무를 나눠 맡고, 곁에서 이야기를 들어주는 등 심리적인 부담을 덜어주려고 노력했습니다. 작은 관심과 공감이 팀 사기를 높이는 데 큰 도움이 되었습니다.  

> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> 졸업작품과 취업 준비가 겹쳐서 체력적으로도 정신적으로도 지치는 시기가 있었습니다.  
> 스스로 동기부여를 유지하기 위해 매일 일정 끝에 소감 기록을 남겼고, 팀원들에게도 짧은 회고 타임을 제안했습니다.  
> 이를 통해 서로 격려하고 장점을 발견하는 분위기가 생기면서, 마감도 무사히 넘길 수 있었습니다.  
>   
> [현직 개발자로, 이직 면접이라면?]  
> 1년간 긴 유지보수 업무가 이어지며 팀 전체 사기가 저하되던 시기가 있었습니다.  
> 작은 성공도 주간 회고에서 공유하고, '미니 챌린지'라는 이름으로 스스로 성장 주제를 정해 발표하는 시간을 만들었습니다.  
> 팀원들 사이에 다시 자율성과 성취감이 생기면서 분위기와 퍼포먼스가 함께 회복되었습니다.   
{: .block-tip } 

---

<br>
<br>
<br>


# 2025.04.14
## 컨테이너화 및 오케스트레이션 도구를 통해 개발/배포 환경을 효율화한 사례가 있다면, 그 방식과 효과를 구체적으로 설명해 주세요.
> 카테고리: 공통, 컨테이너화와 오케스트레이션

> 힌트: 단순히 Docker를 사용해봤다는 수준을 넘어서, 실제 어떤 문제를 해결하기 위해 도입했는지를 중심으로 풀어주는 게 좋습니다.GitOps 방식, Canary 배포, 자동 스케일링 등의 키워드를 함께 언급하시면 실전 경험이 잘 드러납니다.

### 답변
서비스를 구성하는 15개의 Helm 차트를 Umbrella Chart 구조로 통합하여 총 4개의 주요 차트로 구성했습니다.  
이 과정에서 각 서비스의 역할과 의존성을 기준으로 그룹을 나누고, 환경에 따라 자주 변경되는 설정들은 최상위 차트에서 하나의 values 파일로 관리할 수 있도록 구조를 개선했습니다.  
이를 통해 배포 시 각 차트 내부를 직접 수정할 필요 없이, 상단 설정만으로 일관된 구성이 가능해졌고, Helm 설치 명령어 호출 횟수도 줄어 전체 배포 프로세스를 크게 간소화할 수 있었습니다.  
실제로는 배포 시간이 단축되고 설정 실수도 줄어들어 운영 안정성과 유지보수 효율성이 크게 향상되는 효과를 얻을 수 있었습니다.  

> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> 학부 프로젝트에서 도커를 활용해 개발 환경을 통일한 경험이 있습니다.  
> 개발자마다 로컬 환경이 달라 빌드 오류가 잦았는데, Dockerfile을 설정해 공통 환경을 구성했고, 팀원 전원이 동일한 환경에서 개발할 수 있도록 만들었습니다.  
> 이후 GitHub Actions를 통해 이미지 빌드 및 테스트 자동화를 구성하면서, 실무에 가까운 CI/CD 흐름을 경험할 수 있었습니다.  
>   
> [현직 개발자로, 이직 면접이라면?]  
> EKS 기반 마이크로서비스에서 배포 자동화를 위해 ArgoCD를 도입했습니다.  
> 각 서비스는 Helm chart로 구성해 공통 배포 규칙을 관리했고, GitOps 방식으로 운영하면서 배포 오류율이 70% 이상 감소했습니다.  
> 또한 HPA를 연동해 트래픽 급증 시 자동 스케일링이 가능해졌고, Canary 배포 전략으로 무중단 배포까지 구현했습니다.  
{: .block-tip } 

## 프로젝트나 팀 활동 중 리더십을 발휘했던 경험이 있다면, 어떤 방식으로 팀을 이끌었고 어떤 결과를 냈는지 설명해 주세요.
> 카테고리: 인성, 리더십 발휘 순간

> 힌트: 팀원 간 의견 차이나 일정 위기 등 구체적인 상황에서 어떻게 조율하고 리드했는지가 중요합니다. 주도적으로 흐름을 바꿨던 순간이나, 팀 분위기·성과에 긍정적인 영향을 미친 행동이 잘 드러나야 실무형 리더십으로 인정받을 수 있습니다.

### 답변  
CSAP인증을 위한 기술 지원 프로젝트를 진행하던 중, 한 팀원이 과중한 업무로 인해 진행을 하지 못해 전체 일정에 지연이 발생하고 있었습니다.  
이를 해결하기 위해 저는 팀 전체의 업무 현황을 정리하고, 우선 순위를 조율한 후, 해당 팀원이 맡은 업무를 다른 팀원들과 분담할 수 있도록 재조정 했습니다.  
특히, 해당 팀원이 업무를 세분화해서 처리하는 데 어려움을 겪고 있었기 때문에, 몇 차례 함께 업무를 분해하고 계획을 세우는 방식으로 도왔습니다.  
그 결과 팀원은 자신감을 회복하고 업무를 제 시간에 마무리 할 수 있었고, 팀 전체 일정도 원래 계획대로 진행할 수 있었습니다.    
저는 이 경험을 통해, 주어진 업무를 ‘내 일’로만 한정하지 않고 ‘팀의 일’로 바라보며 협업하는 자세와 팀원의 역량까지 함께 끌어올릴 수 있는 리더십의 중요성을 느꼈습니다.   

> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> 팀 프로젝트에서 일정이 자꾸 밀려 팀 분위기가 가라앉은 상황이 있었습니다.  
> 제가 먼저 팀원들과 일정을 다시 정리하고 우선순위를 조정해 '작동하는 기능부터 완성하자'는 MVP 전략을 제안했습니다.  
> 이후 팀원 간 협업이 원활해졌고 프로젝트도 제시간에 마무리할 수 있었습니다.  
>   
> [현직 개발자로, 이직 면접이라면?]
> 신규 기능 런칭 프로젝트에서 PO가 중간 이탈해 일정이 크게 흔들린 적이 있습니다.  
> PM 부재 상태에서 주도적으로 요구사항 정리, 스프린트 재계획, QA 체크리스트 작성 등을 리드했고, 릴리즈를 무사히 완료했습니다.  
> 이후 회고에서 해당 경험이 계기가 되어 팀 내 기술 PM 역할을 제안받기도 했습니다.  
{: .block-tip } 


---

<br>
<br>
<br>

# 2025.04.11
## 분산 시스템에서 서비스 장애나 노드 장애가 발생했을 때, 복구 전략이나 재시작 로직을 설계하면서 고려했던 요소와 실제 경험이 있다면 설명해주세요.
> 카테고리: Backend, 분산 시스템 장애 복구

> 힌트: 장애 탐지 방법, 복구 전략(자동/수동), 데이터 정합성 유지 방법, 장애 전파 방지 등의 관점에서 설명해 보세요. 실제 경험이 없다면 학습한 내용이나 토이 프로젝트에서 고려했던 부분을 공유해도 좋습니다.

### 답변 
Kubernetes 클러스터는 대표적인 분산 시스템 환경으로, 분산 시스템에서는 장애가 언제 어디서든 발생할 수 있기 때문에, 장애 감지, 장애 전파 방지, 복구의 세 가지 관점에서 전략을 수립하는 것이 중요합니다.  
    
실제로 저는 Prometheus와 Alertmanager를 활용한 모니터링 및 알람 체계를 구축하여, 시스템 및 애플리케이션의 이상 징후를 빠르게 감지하고 대응할 수 있도록 구성한 경험이 있습니다. 또한 노드 간 시간 동기화를 통해 로그 및 메트릭의 정합성을 보장해 문제 원인 분석의 신뢰도를 높였습니다.    
    
장애 전파를 방지하기 위해 Kubernetes의 affinity/anti-affinity 설정을 활용하여 워크로드가 특정 노드에 몰리지 않도록 하였고, 이를 통해 한 노드의 장애가 전체 서비스에 영향을 주지 않도록 구성했습니다.    
    
복구 측면에서는, 애플리케이션 레벨에서 Readiness/Liveness Probe를 설정하여 비정상적인 상태의 Pod를 자동으로 재시작하거나 서비스에서 제외되도록 처리하였습니다.    

> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> Kafka를 활용한 데이터 파이프라인을 구성하던 토이 프로젝트에서, consumer가 중단되면 메시지를 처리하지 못해 데이터 누락 문제가 발생했습니다.  
> 이후 오프셋을 명시적으로 관리하고, 실패 시에는 일정 시간 간격을 둔 재시도 로직을 추가했습니다.  
> 단순히 메시지를 처리하는 것뿐 아니라, 실패 가능성을 고려한 복구 구조의 중요성을 느낀 경험이었습니다.  
>   
> [현직 개발자로, 이직 면접이라면?]  
> 실시간 통계 수집 시스템에서 노드 장애가 발생하면서 결과 데이터 누락 문제가 생긴 적이 있었습니다.  
> 장애 탐지와 상태 복구를 위해 Redis 기반 상태 저장, liveness probe 설정, 그리고 서킷 브레이커 패턴을 적용했습니다.  
> 또한 Kafka 메시지의 idempotent 처리, DLQ 설정까지 함께 구성해 장애 복구 시 데이터의 정합성을 유지할 수 있도록 했습니다.  
> 결과적으로 운영 중단 없이 자동 복구가 가능해졌고, 재현 테스트도 안정적으로 통과할 수 있었습니다.  
{: .block-tip }  

## 데이터베이스 성능 이슈를 경험하고 이를 해결한 경험이 있다면 공유해주세요. 어떤 문제가 있었고, 어떤 방식으로 진단하고 개선했는지 설명해주세요.
> 카테고리: Backend, 데이터베이스 최적화 경험

> 힌트: 인덱스 최적화, 쿼리 튜닝, 데이터 모델링 개선, 캐싱 도입 등의 경험을 떠올려보세요. 성능 측정 방법과 개선 효과도 함께 설명하면 좋습니다.

### 답변 
사이드 프로젝트에서 콘서트 일정 조회 시 성능 이슈를 겪었습니다. concert_id 기준으로 약 150개 정도의 데이터만 조회되지만, 인덱스가 제대로 활용되지 않아 테이블 스캔이 발생했습니다.   
문제의 원인은 카디널리티가 낮아 인덱스 효용이 떨어졌기 때문이었습니다. 이를 해결하기 위해 조회 조건에 맞는 조합 인덱스를 재설계하고, 쿼리 실행 계획을 분석하며 최적화했습니다.    
k6를 이용해 성능 테스트한 결과 쿼리 비용과 실행 시간을 개선했습니다. 이 경험을 통해 단순히 인덱스를 추가하는 것보다 카디널리티와 실행 계획 분석이 더 중요하다는 점을 배웠습니다.  

> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> 토이 프로젝트에서 게시글 목록을 불러올 때 페이지 로딩이 느려지는 문제가 있었습니다. 개발 도구로 확인해보니 DB 쿼리 실행 시간이 길었고, EXPLAIN 명령어로 분석한 결과 인덱스가 제대로 활용되지 않고 있었습니다. 게시글 테이블에 복합 인덱스를 추가하고, 페이지네이션 쿼리를 최적화한 결과 조회 시간이 2초에서 0.3초로 단축되었습니다.  
>   
> [현직 개발자로, 이직 면접이라면?]  
> 실시간 대시보드 서비스에서 사용자가 늘어나면서 DB 부하가 증가하고 응답 시간이 10초 이상으로 늘어나는 문제가 발생했습니다. 프로파일링 결과, 자주 조회되는 통계 데이터를 매번 계산하는 것이 원인이었습니다. 이를 해결하기 위해 Redis를 도입해 계산된 결과를 캐싱하고, 배치 작업으로 주기적으로 갱신하는 방식으로 변경했습니다. 또한 자주 사용되는 쿼리에 적절한 인덱스를 추가하고, 일부 테이블은 파티셔닝을 적용했습니다. 결과적으로 평균 응답 시간이 0.5초 이내로 개선되었고, DB 서버 부하도 70% 감소했습니다.  
>     
> [첫 취업 준비생이라면?]  
> 사이드 프로젝트에서 특정 게시글 리스트 API가 매우 느려지는 현상이 있었고, 쿼리를 분석해보니 날짜 필드 정렬 시 인덱스가 적용되지 않는 문제가 있었습니다.  
> 이를 해결하기 위해 복합 인덱스를 생성했고, DB 조회 속도가 3초 → 0.3초로 개선되었습니다.  
> 처음엔 단순히 LIMIT 문제로 생각했지만, 실제 실행 계획(EXPLAIN) 확인의 중요성을 알게 되었습니다.  
>   
> [현직 개발자로, 이직 면접이라면?]  
> 거래 데이터가 수억 건 누적된 테이블에서 정산 리포트 API의 성능 문제가 발생했습니다.  
> 비정규화 테이블을 분리하고 파티셔닝 전략과 인덱스 튜닝, 읽기 전용 슬레이브를 통한 부하 분산을 적용해 평균 응답 속도를 5초 → 0.7초로 줄였습니다.  
> 이외에도 slow query 로그 기반으로 인덱스 통계를 정리해 매월 리팩토링 주기를 운영했습니다.  
{: .block-tip }  


## 프로젝트에서 기술 부채를 어떻게 정의하고, 그것을 정량화하거나 체계적으로 관리해본 경험이 있다면 설명해주세요. 그 과정을 통해 어떤 효과가 있었는지도 함께 이야기해주세요.
> 카테고리: 공통, 기술 부채 관리

> 힌트: 기술 부채는 빠른 개발을 위해 나중에 갚기로 한 '빚' 같은 기술적 타협을 말하며, 코드 중복, 테스트 누락, 문서화 부족 등도 포함됩니다. 기술 부채에 대한 정량화 기준(예: PR backlog, 테스트 커버리지 등), 대응 방식(Refactor Sprint, 주간 점검 등)을 중심으로 답변해 보세요.

### 답변 
프로젝트 진행 중, 서비스 내 소프트웨어 간 의존성이 명확하지 않아 기능 별로 어떤 서비스가 필수인지, 선택적인지 파악하기 어려운 문제가 있었습니다. 저는 이를 기술 부채로 인식하고, 시스템 전반의 구성과 의존 관계를 시각화 하여 문서화 하는 작업을 수행했습니다.  
  
각 소프트웨어의 역할과 중요도를 정리하고, 필수 여부, 요청 흐름, 이미지 및 버전 정보 등을 포함한 도식화된 문서를 체계적으로 관리함으로써, 기술 부채를 줄이고 서비스 구조의 명확성을 높였습니다.  

> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> 팀 프로젝트에서 일정이 촉박해 공통 컴포넌트를 빠르게 하드코딩 방식으로 처리한 적이 있습니다.  
> 나중에는 같은 컴포넌트에 반복적으로 수정이 들어가면서 유지보수가 어려워졌고, 이걸 계기로 리팩토링 전용 스프린트를 따로 만들었습니다.  
> 기능과 속도만 보던 초반과 달리, 이후엔 기술 부채도 하나의 '관리 대상'으로 인식하게 되었고, 지금은 설계 단계에서부터 중복과 확장 가능성을 의식하려 노력하고 있습니다.  
>   
> [현직 개발자로, 이직 면접이라면?]  
> 사내 프로젝트에서 테스트 커버리지 부족, 중복 로직, 복잡한 조건문이 점점 쌓이면서 개발 속도도 떨어지고 버그 빈도가 높아졌습니다.  
> 이를 해결하기 위해 기술 부채 점검 기준을 팀 차원에서 정리하고, 매 스프린트마다 일정 비율로 리팩토링 태스크를 포함했습니다.  
{: .block-tip }  

## 기존 코드베이스에서 리팩토링을 진행한 경험이 있다면, 어떤 문제를 발견했고 어떻게 개선했는지 설명해주세요. 리팩토링 전후의 차이점과 그 결과도 함께 공유해주세요.
> 카테고리: 공통, 코드 리팩토링 경험

> 힌트: 리팩토링은 외부 동작을 바꾸지 않으면서 내부 구조를 개선하는 과정입니다. 코드 중복 제거, 함수 분리, 클래스 재구성 등의 경험을 떠올려보세요.

### 답변   
Elasticsearch에 저장된 이미지 메타데이터를 조회하는 API에서, 데이터 양이 많아지면서 로딩 시간이 점점 길어지는 문제가 발생했습니다.  
기존에는 from과 size를 이용한 오프셋 기반 페이지네이션 방식을 사용하고 있었는데, 이 방식은 데이터가 많아질수록 성능 저하가 발생하는 구조였습니다.  
  
이 문제를 해결하기 위해 search_after를 도입하여 페이지네이션 방식을 개선했습니다. search_after는 오프셋을 사용하지 않고, 특정 정렬 기준 이후의 데이터를 탐색하기 때문에 대용량 데이터 처리에 훨씬 효율적입니다.  
정렬 기준은 고유성과 정렬 안정성이 보장된 id 필드를 사용하여, 기존의 오프셋 기반 페이지네이션을 커서 기반 방식으로 전환했습니다.  
  
클라이언트 요청 형식은 기존과 동일하게 유지하면서, 내부적으로만 search_after 기반 구조로 변환하여 외부 API 인터페이스는 변경 없이 성능 개선을 이끌어낼 수 있었습니다.  


> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> 팀 프로젝트에서 API 호출 로직이 여러 컴포넌트에 중복되어 있어 유지보수가 어려웠습니다. 이를 개선하기 위해 공통 훅(custom hook)으로 분리하고, 에러 처리와 로딩 상태 관리도 일관되게 처리했습니다. 리팩토링 후에는 코드량이 30% 정도 줄었고, 새로운 API 연동 시 개발 시간도 크게 단축되었습니다.  
>   
> [현직 개발자로, 이직 면접이라면?]  
> 레거시 프로젝트에서 비즈니스 로직과 UI 로직이 혼재된 컴포넌트를 발견했습니다. 이로 인해 테스트가 어렵고 기능 확장 시 사이드 이펙트가 자주 발생했습니다. 이를 개선하기 위해 Presenter-Container 패턴을 적용해 비즈니스 로직을 분리하고, 단위 테스트를 추가했습니다. 결과적으로 테스트 커버리지가 40%에서 75%로 증가했고, 이후 기능 추가 시 버그 발생률이 60% 감소했습니다.  
{: .block-tip }  

## 팀 내에서 기술적 의견 차이가 있었던 상황에서, 본인의 입장을 유지하면서도 상대와 타협하거나 협상을 이끌어낸 경험이 있다면 공유해주세요.
> 카테고리: 인성, 의견 충돌과 협상

> 힌트: 기술 선택, 일정 조율, 코드 스타일, 구현 방식 등에서 갈등이 생길 수 있습니다. 여기서 포인트는 "무작정 고집"이 아니라, 근거 기반 설득 → 협상 → 합의 도출의 과정이며, 자신이 제안한 방식이 채택되지 않아도, 과정이 건강했다면 좋은 예입니다!

### 답변 
개발팀에서 인공지능 모델의 학습 및 추론 컨테이너 실행 시간만큼 마일리지를 차감하는 기능을 설계하던 중, 컨테이너 실행 시간을 측정하는 기준을 두고 의견 차이가 있었습니다.
일부 팀원은 Kubernetes API를 통해 서비스에서 컨테이너를 생성한 시점과 종료 시점을 기준으로 삼자고 했지만, 이 경우 컨테이너가 실제로 준비되기 전 시간까지 포함되어 정확한 사용 시간 측정에 오차가 생기는 문제가 있었습니다.  
  
저는 이러한 문제를 해결하기 위해 Kubernetes Audit 로그를 활용하자는 대안을 제시했습니다. Audit 로그를 통해 컨테이너 상태 변화와 정확한 시간 정보를 가져올 수 있으며, 이를 기반으로 하면 실제 사용 시간만 정확하게 추출할 수 있었습니다.  
  
팀원들과의 논의 끝에 제 의견이 받아들여졌고, 이를 기반으로 기능을 구현하여 요구사항에 부합하면서도 신뢰도 높은 시간 측정 로직을 완성할 수 있었습니다.   

> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> 팀 프로젝트에서 UI 라이브러리를 통일할지 각자 사용하는 방식대로 진행할지를 두고 팀원과 의견이 엇갈렸습니다.  
> 저는 유지보수와 코드 통일성 측면에서 통일된 라이브러리가 낫다고 주장했고, 그 근거를 문서로 정리한 뒤 공유했습니다.  
> 결과적으로 토론 끝에 메인 기능은 통일된 라이브러리를 쓰되, 부가 기능은 자유롭게 구현하기로 타협점을 찾을 수 있었습니다.  
> 
> 
> [현직 개발자로, 이직 면접이라면?]  
> 코드 리뷰 중 유틸 함수의 책임 분리를 두고 팀원과 충돌이 있었습니다. 저는 단일 책임 원칙에 따라 분리를 제안했고, 팀원은 복잡성 증가를 우려했습니다.  
> 이에 기존 코드에서 발생했던 유지보수 이슈를 기반으로 설명하고, 일단 분리해 적용 후 회고에서 다시 검토하기로 했습니다.  
> 최종적으로는 설계의 장점이 입증되었고, 팀의 기술 토론 문화가 더 성숙해지는 계기가 되었습니다.  
{: .block-tip }  

---

<br>
<br>
<br>

# 2025.04.10  
## 마이크로서비스 혹은 분산 시스템에서 데이터 일관성을 유지하기 위한 전략을 고민하거나 적용한 경험이 있다면 공유해주세요. 규모가 작아도 서비스 간 데이터 처리 흐름을 설계해본 경험이면 충분합니다.
> 카테고리: Backend, 마이크로서비스 데이터 일관성

> 힌트: 단일 DB 트랜잭션이 아닌, 서비스 간 데이터 일관성을 유지하는 방식을 고민해본 경험을 떠올려 보세요. (예: Eventual Consistency, 이벤트 기반 처리, SAGA 패턴 등)

### 답변
사이드 프로젝트에서 좌석 예약 시스템을 개발한 경험이 있습니다.
예약이 완료되면 해당 정보를 데이터 플랫폼 시스템에서 활용할 수 있도록 이벤트를 발행하는 구조였고,
두 시스템은 각각 마이크로서비스 형태로 분리되어 있었습니다.

그런데 간혹 좌석 예약은 정상적으로 처리되었지만, 이벤트가 유실되거나 발행에 실패하는 문제가 발생했습니다.
이로 인해 실제 예약 정보가 데이터 플랫폼 쪽에 반영되지 않는 등, 서비스 간 데이터 정합성이 깨지는 이슈가 생길 수 있는 구조였습니다.

이를 해결하기 위해, 이벤트 발행 이후 동일 메시지를 내부 Kafka Consumer로 consume하여, 발행이 실제로 처리되었는지를 검증하는 구조를 도입했습니다.
이 과정에서 발행 실패 시 재발행을 시도하고, 일정 횟수 이상 실패할 경우에는 로그로 기록하고 수동 조치가 가능하도록 처리했습니다.

이 구조 덕분에 비동기 환경에서도 데이터 정합성을 어느 정도 보장할 수 있었고, 전체 시스템의 안정성도 향상되었습니다.
추후에는 DLQ(Dead Letter Queue)와 같은 메시지 유실 방지 장치를 도입하여 더욱 견고한 구조로 보완할 계획도 세웠습니다.

이 경험을 통해, 마이크로서비스 간 데이터 흐름에서는 보상 전략, 실패 검증, 장애 복구 수단까지 함께 고려해야 한다는 교훈을 얻을 수 있었습니다.

> ##### 모범 답안
> 
> [첫 취업 준비생이라면?]  
> 토이 프로젝트에서 사용자 서비스와 결제 서비스를 나누어 구현했는데, 결제 완료 후 사용자 상태를 업데이트하는 로직이 REST API 방식의 동기 호출되다 보니 결제 실패 시 사용자 상태가 잘못 변경되는 문제가 있었습니다. 이를 해결하기 위해 RabbitMQ를 도입해 결제 완료 시 이벤트 메시지를 발행하고, 사용자 서비스가 이를 구독해 상태를 변경하도록 했습니다. 비록 작은 프로젝트였지만, 서비스 간의 의존도를 줄이고 일관된 흐름을 유지하기 위해 비동기 메시징이 필요하다는 것을 체감할 수 있었습니다.
>   
> [현직 개발자로, 이직 면접이라면?]  
> 커머스 시스템에서 주문, 결제, 배송 서비스를 마이크로서비스로 분리한 이후, 주문 생성 후 결제 실패 시 데이터 정합성 이슈가 발생했습니다. 이를 해결하기 위해 SAGA 패턴을 기반으로 한 이벤트 드리븐 구조를 도입했고, Kafka를 이벤트 브로커로 사용해 서비스 간 데이터를 전달했습니다. 실패 시 보상 트랜잭션을 통해 이전 상태로 복구하는 로직을 각 서비스에 구현했으며, idempotent key 처리, DLQ 설계 등도 함께 적용해 안정성을 높였습니다. 결과적으로 연관 서비스 간 장애 전파율이 줄고 유지보수 ㄴ비용도 감소했습니다.
{: .block-tip }  

## 기존 코드베이스에 새로운 기술이나 도구를 도입했던 경험이 있다면, 어떤 리스크를 고려했고, 이를 어떻게 관리했는지 설명해주세요. 실무 경험이 없다면 팀 프로젝트나 사이드 프로젝트에서 고민했던 사례를 공유해 주세요.
> 카테고리: 공통, 기술 도입 시 리스크 관리

> 힌트: 도입 기술은 프레임워크, 상태 관리 도구, 빌드 시스템, 배포 도구 등 다양합니다. 기존 시스템과의 충돌, 학습 비용, 유지보수 리스크 등을 고려해 본 경험을 공유하세요.

### 답변  
Kubernetes 클러스터에 여러 기관의 플랫폼을 설치해야 했던 프로젝트에서, 
한 번에 다수의 플랫폼을 배포해야 했기 때문에 시간이 오래 걸리고 반복 작업도 많았습니다.  
  
당시에는 프로젝트 관리자나 운영팀이 직접 설치를 수행해야 하는 경우도 있었고, Helm 명령어 기반 배포 과정의 복잡성으로 인해 러닝 커브도 높은 상황이었습니다.  
  
이 문제를 해결하기 위해 '버튼 클릭만으로 배포 가능한 기능'을 목표로 설정했고, 
핵심 기술로 Helm Operator(Helm Controller)를 도입했습니다.  
Helm Operator는 Helm 차트를 Kubernetes 커스텀 리소스로 등록하고, 이를 자동으로 배포·관리할 수 있게 해주기 때문에, 기존 Helm 구조는 유지하면서도 자동화 수준을 높일 수 있는 장점이 있었습니다.    
   
기술 도입 당시 고려한 사항은 크게 3가지 였습니다.      
- 운영팀의 부담 최소화 하기위해 기존 Helm 배포 방식을 그대로 유지할 수 있는지 
- 새로운 컨트롤러 도입에 따른 리소스 관리 복잡도가 증가 하는지    
- 배포 실패 시 롤백 전략 및 오류 추적이 가능한지  
  
결과적으로 운영팀은 복잡한 설치 과정을 몰라도 UI에서 간단한 입력만으로 배포할 수 있게 되었고, 서비스 배포 시간도 단축되었습니다.  
  
이 경험을 통해, 새로운 기술 도입은 단순히 좋아 보여서 하는 것이 아닌, 기존 환경과 사용자 경험까지 함께 고민해야 한다는 것을 배웠습니다.   

> ##### 모범 답안
> 
> [첫 취업 준비생이라면?]  
> 졸업작품에서 Redux를 사용하던 기존 코드에 일부 기능만 Recoil로 바꿔보려 했던 적이 있습니다. 하지만 프로젝트 후반에 두 상태 관리 방식이 혼재되면서, 어떤 데이터가 어디서 변경되는지를 추적하기 어려워졌고, 디버깅 시간이 급증했습니다. 이를 해결하기 위해 팀원들과 함께 상태 관리 방식을 통일하기로 결정했고, Recoil로 전면 전환하되 이전 구조와의 차이점을 문서로 남겨 이후 팀원들이 적응할 수 있도록 했습니다. 이 경험을 통해 새로운 기술 도입은 기능 중심이 아니라 유지보수성과 팀 전체의 이해도까지 고려해야 한다는 교훈을 얻었습니다.
>   
> [현직 개발자로, 이직 면접이라면?]  
> 사내에서 오래된 Gulp 기반 빌드 환경을 유지하던 프로젝트가 있었습니다. 기능이 많아지면서 빌드 시간이 길어지고, 일부 플러그인은 유지보수가 어려워져 문제가 반복됐습니다. 이를 해결하기 위해 Webpack 기반 환경으로 점진적 전환을 제안했고, 기존 Gulp task를 하나씩 Webpack config로 이관하는 방식으로 진행했습니다. 특히 코드 분할(Code Splitting), HMR 도입 등으로 로컬 개발 빌드 시간이 평균 30% 단축되었고, 에러 추적도 쉬워졌습니다. 중요한 건 새 도구 자체보다, 기존 시스템과 충돌 없이 점진적으로 바꾸는 과정이었고, 이를 위해 팀 내 문서화와 주간 공유를 병행했습니다.
{: .block-tip }  

## 최근에 실패했던 경험이 있다면 솔직하게 공유해 주세요. 그 실패로부터 무엇을 배우고, 어떻게 성장했는지도 함께 이야기해 주세요. 결과가 좋지 않아도 괜찮습니다.
> 카테고리: 인성, 실패 경험과 교훈

> 힌트: "실패"는 결과가 안 좋았던 프로젝트, 일정 지연, 기술 선택 실패, 협업 문제 등 다양합니다. 이런 질문의 핵심은 실패 자체보다 그 이후의 성찰과 변화가 무엇이었는지 묻는 거예요!

### 답변   
컨테이너 환경에서 GPU를 사용할 수 있도록 NVIDIA Device Plugin을 사용하고 있었습니다. 기존에는 GPU 종류가 바뀌더라도 큰 문제가 없었기 때문에, 설치 파일을 간소화하고 해당 플러그인만 사용하는 방식으로 운영 중이었습니다.

그러나 새로운 A100 GPU 환경에서는 일정 시간이 지나면 컨테이너가 GPU를 인식하지 못하는 문제가 발생했습니다. 당시에는 서비스가 운영 중이었고, 사용자들이 모델 재학습을 시도할 때 GPU 인식 오류로 인해 지속적으로 문의가 들어왔습니다.

문제를 분석해보니, docker daemon-reload가 발생할 때마다 GPU 링크가 끊기는 현상이었고, 이전에 잘 동작했기 때문에 “이번에도 문제없을 것”이라는 안일한 판단으로 충분한 테스트 없이 동일한 방식으로 배포한 것이 원인이었습니다.

이후에는 NVIDIA GPU Operator를 도입하여, GPU 드라이버 및 관련 플러그인을 자동으로 설치하고 링크 상태를 지속적으로 확인하도록 구성했고, 해당 이슈는 재발하지 않았습니다.

이 경험을 통해 작은 환경 변화라고 하더라도 테스트를 철저히 해야 한다는 점을 크게 느꼈습니다. 이후로는 환경이 조금이라도 변경되면 꼭 세세하게 검증을 마친 후에 배포하는 습관을 갖게 되었습니다.

> ##### 모범 답안
> 
> [첫 취업 준비생이라면?]  
> 팀 프로젝트 중 더 완성도 높은 결과물을 만들고 싶다는 욕심에, 개발 도중 기획을 확장하다 보니 마감 기한을 지키지 못했습니다. 특히 복잡한 필터링 기능을 추가했는데, 예상보다 많은 시간과 버그가 발생했고 팀원들의 부담도 커졌습니다. 이 경험을 통해 '무엇을 얼마나 잘 구현할 것인가'도 중요하지만, MVP를 명확히 정의하고 우선순위를 조율하는 것이 프로젝트의 핵심이라는 걸 배웠습니다. 이후엔 모든 프로젝트에서 이 부분을 가장 먼저 체크하고 있습니다.
>   
> [현직 개발자로, 이직 면접이라면?]  
> 첫 이직 후, 전 직장에서 쓰지 않던 GraphQL을 사용하는 프로젝트에 투입되었는데, 생소한 도구와 도메인 때문에 문제를 스스로 해결하려다 기능 배포가 지연된 적이 있습니다. "적응 중인데 민폐를 끼치기 싫다"는 생각에 요청을 미뤘지만, 오히려 팀에 부담을 준 결과였죠. 이후 팀 리더와 회고를 진행했고, 그 뒤로는 작은 어려움도 빠르게 공유하고 온보딩 기술 공유 세션을 자발적으로 운영했습니다. 이 경험은 "성장 = 혼자 해결"이라는 고정관념을 깬 계기가 되었고, 지금은 신규 입사자들의 질문을 먼저 들어주는 입장이 되었습니다.
{: .block-tip }  

---

<br>
<br>
<br>

# 2025.04.09
## RESTful API를 설계할 때 고려해야 할 주요 원칙들에 대해 설명하고, 좋은 RESTful API의 예시를 들어주세요.
> 카테고리: Backend, RESTful API 설계 원칙  

> 힌트: 자원(Resource), 행위(Verb), 표현(Representation)의 개념을 고려해보세요.

### 답변
RESTful API는 자원을 URL로 표현하고, 행위는 HTTP 메서드(GET, POST, PUT, DELETE 등)로 구분하며, 자원의 상태는 JSON 같은 표현 형식으로 주고받는 구조입니다.  
이러한 구조를 위해서는 각 요청을 독립적으로 만들고, 일관된 방식으로 리소스를 처리하게 하여 무상태성과 일관된 인터페이스 원칙을 지켜야 하며, 자원 기반 구조(Resource-Oriented Architecture), HTTP 메서드를 통한 행위 표현(Method Semantics), 표현을 통한 상태 전달(Representation of Resource State) 을 고려해야 합니다.  

> ##### 모범 답안
> 
> RESTful API 설계의 주요 원칙은  
> 1) 자원 기반 구조(URI로 자원 표현),  
> 2) HTTP 메서드를 통한 행위 표현(GET, POST, PUT, DELETE),   
> 3) 무상태성(Stateless),   
> 4) 캐시 가능성,   
> 5) 계층화된 시스템,   
> 6) 통일된 인터페이스입니다.   
> 좋은 예시로는 GitHub API가 있으며, 자원을 명확히 표현하고 적절한 HTTP 메서드를 사용합니다.
{: .block-tip } 


## 동시성 문제란 무엇이며, 이를 해결하기 위한 기본적인 전략을 설명해주세요. 실제 운영 환경에 적용한 사례가 있다면 함께 설명해 주어도 좋습니다.
> 카테고리: Backend, 동시성 문제 해결  

> 힌트: 동시성은 다중 사용자/요청이 동시에 자원에 접근할 때 발생합니다. 락(lock), 큐(queue), 트랜잭션 격리 수준 등의 개념을 활용해 본 경험을 떠올려 보세요.

### 답변
동시성 문제란, 여러 개의 프로세스나 스레드가 동시에 하나의 공유 자원에 접근할 때, 예상치 못한 결과나 데이터 정합성 문제가 발생하는 현상을 말합니다. 예를 들어 동시에 같은 좌석을 예약하거나, 동일한 재고를 두 번 차감하는 상황이 이에 해당합니다.  
  
이러한 문제를 해결하기 위한 기본적인 전략으로는 락(Lock) 메커니즘, 트랜잭션 격리 수준 설정, 낙관적/비관적 락, 요청 큐잉 등이 있습니다. 락을 사용하면 한 시점에 하나의 쓰레드만 자원에 접근하도록 제한할 수 있으며, 큐는 요청을 순차적으로 처리해 동시에 발생하지 않도록 방지합니다.  
  
실제로 저는 좌석 예약 API를 개발하면서 동시성 문제를 해결한 경험이 있습니다. 특정 공연에 좌석 예약 요청이 동시에 몰리는 상황에서, 이중 예약을 방지하기 위해 Redis 기반의 분산 락(distributed lock)을 적용했습니다. Redis의 SETNX 명령어를 활용해 한 번에 하나의 사용자만 특정 좌석에 접근할 수 있도록 제어했고, 락의 유효 시간을 설정하여 데드락(deadlock)도 방지했습니다. 이를 통해 DB 부하도 줄이고, 안정적인 예약 처리를 할 수 있었습니다.  


> ##### 모범 답안
>
> [첫 취업 준비생이라면?]  
> 동시성 문제는 여러 사용자가 동시에 같은 자원에 접근할 때, 의도하지 않은 결과가 생기는 현상입니다. 예를 들어, 게시글 추천 수를 동시에 여러 명이 누르면 실제 추천 수보다 적거나 중복될 수 있습니다. 이를 해결하기 위해 DB에서 트랜잭션을 활용하거나, 어플리케이션 단에서는 락을 사용하는 방법을 학습했습니다. 개인 프로젝트에서 단순한 예시로 Python에서 threading을 사용한 카운터 처리에서 race condition을 실험하고 해결한 적이 있습니다.
> 
> [현직 개발자로, 이직 면접이라면?]  
> 실제 운영 중이던 커머스 서비스에서, 주문 수량 처리 중 동시성 이슈로 재고가 마이너스로 떨어지는 문제가 있었습니다. 해결을 위해 Redis를 활용한 분산 락 시스템(Redlock)을 도입했고, 동시에 트랜잭션의 격리 수준을 Read Committed → Repeatable Read로 조정했습니다. 이후에는 race condition 없이 재고 처리가 안정적으로 이루어졌고, 동시에 예약 처리가 필요한 기능에도 확장 적용할 수 있었습니다.
{: .block-tip }  

## 최근 5년간 발전한 기술 트렌드 중, 당신의 개발 방식 또는 학습 방식에 가장 큰 영향을 준 기술은 무엇인가요? 그 이유와, 실제로 적용해 보았거나 흥미롭게 느꼈던 경험이 있다면 함께 설명해 주세요.

> 카테고리: 공통, 최신 기술 트렌드의 영향

> 힌트: "기술 트렌드"는 AI, 클라우드, 프레임워크 변화, DevOps 도구 등 다양합니다. 학습 방식이나 개발 철학에 영향을 준 경험 중심으로 이야기해 보세요.

### 답변
최근 5년간 저에게 가장 큰 영향을 준 기술은 Kubernetes입니다. 클라우드 네이티브 환경이 표준화되면서, Kubernetes는 인프라 설계의 핵심 도구로 자리잡았고, 저는 이 과정에서 ‘기술을 구조적으로 이해하는 습관’을 갖게 되었습니다.

Kubernetes는 내부적으로 다양한 개념을 자체 용어와 방식으로 추상화해 제공하는데, 이 덕분에 새로운 기술을 학습할 때 기존 개념과 연결해 이해하거나, 제 방식대로 재구성하여 이해하는 학습 습관을 갖게 되었습니다.

실제로 온프레미스 환경에서 인프라를 구성할 때도, Kubernetes의 리소스 설계와 개념을 참조하여 방화벽, 로드밸런서, DNS 구성 등 다양한 요소를 클라우드 개념에 빗대어 정리할 수 있었고, 덕분에 팀원들과의 소통도 훨씬 원활했습니다.

이 경험을 통해 단순히 기술을 ‘쓸 줄 아는 것’을 넘어, 개념을 추상화하고 내 방식으로 이해하는 능력이 장기적으로 성장하는 데 큰 힘이 된다고 느꼈습니다.

> ##### 모범 답안
>
> [첫 취업 준비생이라면?]  
> 저는 최근 빠르게 발전하고 있는 AI 기반 개발 도구(GitHub Copilot)의 등장이 가장 인상 깊었습니다. 졸업 프로젝트를 진행하면서 처음 사용해 보았는데, 코드 자동완성을 넘어 테스트 함수나 반복 로직의 구조까지 제안해주는 점이 놀라웠습니다. 이 도구 덕분에 단순 구현보다 코드 구조와 설계에 더 집중하는 개발 습관을 기를 수 있었습니다. 실무에 들어가서도 이런 AI 보조 도구를 적극 활용하면 빠르게 성장할 수 있을 것 같다고 느꼈습니다.
> 
> [현직 개발자로, 이직 면접이라면?]  
> 가장 큰 영향을 준 기술은 CI/CD 자동화 환경과 GitHub Actions의 확산입니다. > 반복되는 배포 과정과 QA 자동화를 줄이기 위해 팀 내에서 직접 Actions 워크플로우를 구성하고 운영해본 경험이 있습니다. 특히 QA 테스트 결과에 따라 PR을 자동으로 머지/반려하도록 설정하면서 개발 효율성과 팀 신뢰도가 높아졌습니다. 이러한 경험은 코드 작성뿐만 아니라 팀 내 개발 프로세스 개선까지 주도하는 역량을 키우는 데 도움이 되었습니다.
{: .block-tip }  

## 프로젝트 진행 중 협업 과정에서 갈등이나 의견 차이가 있었던 경험이 있다면, 이를 어떻게 해결했는지 설명해주세요. 그 과정에서 본인이 맡았던 역할과 결과도 함께 알려주세요.

> 카테고리: 인성, 갈등 중재 경험

> 힌트: "갈등"은 코드 스타일, 일정 조율, 기술 선택 등 작은 것도 포함됩니다. 감정적 판단보다 협업과 결과 중심의 해결 노력을 강조해 보세요.

### 답변
프로젝트를 진행하면서, 개발팀이 인지한 기능 완료 범위와 PM이 기대하는 결과물 간에 차이가 있었던 적이 있습니다. 개발팀은 기능 구현이 완료됐다고 판단했지만, 일부 동작이나 UI 흐름에서 기대에 미치지 못하는 부분들이 남아 있었습니다.  
  
당시 저는 배포 담당이었지만, 전체 흐름을 잘 알고 있던 만큼 일정 여유를 활용해 UI 통합 테스트를 진행했습니다. 사용자 관점에서 플로우를 재점검하며, 누락되었거나 매끄럽지 않은 동작을 정리해 개발팀과 PM 양측에 공유했습니다. 이 과정에서 서로의 기준 차이를 조율할 수 있도록 중간자 역할을 수행했습니다.
  
결과적으로, QA 과정에서 발생할 수 있었던 이슈를 사전에 방지했고, 일정 지연 없이 데드라인 내 프로젝트를 성공적으로 마무리할 수 있었습니다. 이 경험을 통해 팀 간 기대치 조율과 사전 커뮤니케이션의 중요성을 실감하게 되었습니다. 

> ##### 모범 답안
>
> [첫 취업 준비생이라면?]  
> 팀 프로젝트 중 백엔드 API 명세를 문서화하는 방식을 두고 의견 차이가 있었습니다. > 어떤 팀원은 Notion, 저는 Swagger UI를 주장했죠. 갈등을 줄이기 위해 각 방식의 장단점을 정리해 공유하고, 실제 구현 테스트도 함께 해보자는 제안을 했습니다. > 결과적으로 Swagger가 자동화와 유지보수 측면에서 낫다는 데 모두 동의했고, 팀워크도 자연스럽게 회복되었습니다.
> 
> [현직 개발자로, 이직 면접이라면?]  
> 코드 리뷰 과정에서 주니어 개발자와 네이밍 규칙을 두고 의견이 충돌한 적이 있습니다. 단순히 지적하기보다, 그 규칙이 왜 필요한지 설명하고 예시를 제시했습니다. > 이후에는 리뷰 문화에 대한 가이드를 팀 내에 문서화했고, 리뷰 가이드 세션도 주도했습니다. 개인적인 의견 차이에서 시작된 갈등을 협업 문화 개선의 기회로 바꾼 경험이었습니다.
{: .block-tip }