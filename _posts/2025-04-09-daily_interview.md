---
title: 2025 챌린지 - 매일 기술 면접 답변하기
author: 한춘식
date: 2025-04-09
category: books
layout: post
toc:
    enabled: true
---  

# 2025.04.11
## 분산 시스템에서 서비스 장애나 노드 장애가 발생했을 때, 복구 전략이나 재시작 로직을 설계하면서 고려했던 요소와 실제 경험이 있다면 설명해주세요.
> 카테고리: Backend, 분산 시스템 장애 복구

> 힌트: 장애 탐지 방법, 복구 전략(자동/수동), 데이터 정합성 유지 방법, 장애 전파 방지 등의 관점에서 설명해 보세요. 실제 경험이 없다면 학습한 내용이나 토이 프로젝트에서 고려했던 부분을 공유해도 좋습니다.

### 답변 
Kubernetes 클러스터는 대표적인 분산 시스템 환경으로, 분산 시스템에서는 장애가 언제 어디서든 발생할 수 있기 때문에, 장애 감지, 장애 전파 방지, 복구의 세 가지 관점에서 전략을 수립하는 것이 중요합니다.  
    
실제로 저는 Prometheus와 Alertmanager를 활용한 모니터링 및 알람 체계를 구축하여, 시스템 및 애플리케이션의 이상 징후를 빠르게 감지하고 대응할 수 있도록 구성한 경험이 있습니다. 또한 노드 간 시간 동기화를 통해 로그 및 메트릭의 정합성을 보장해 문제 원인 분석의 신뢰도를 높였습니다.    
    
장애 전파를 방지하기 위해 Kubernetes의 affinity/anti-affinity 설정을 활용하여 워크로드가 특정 노드에 몰리지 않도록 하였고, 이를 통해 한 노드의 장애가 전체 서비스에 영향을 주지 않도록 구성했습니다.    
    
복구 측면에서는, 애플리케이션 레벨에서 Readiness/Liveness Probe를 설정하여 비정상적인 상태의 Pod를 자동으로 재시작하거나 서비스에서 제외되도록 처리하였습니다.    

> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> Kafka를 활용한 데이터 파이프라인을 구성하던 토이 프로젝트에서, consumer가 중단되면 메시지를 처리하지 못해 데이터 누락 문제가 발생했습니다.  
> 이후 오프셋을 명시적으로 관리하고, 실패 시에는 일정 시간 간격을 둔 재시도 로직을 추가했습니다.  
> 단순히 메시지를 처리하는 것뿐 아니라, 실패 가능성을 고려한 복구 구조의 중요성을 느낀 경험이었습니다.  
>   
> [현직 개발자로, 이직 면접이라면?]  
> 실시간 통계 수집 시스템에서 노드 장애가 발생하면서 결과 데이터 누락 문제가 생긴 적이 있었습니다.  
> 장애 탐지와 상태 복구를 위해 Redis 기반 상태 저장, liveness probe 설정, 그리고 서킷 브레이커 패턴을 적용했습니다.  
> 또한 Kafka 메시지의 idempotent 처리, DLQ 설정까지 함께 구성해 장애 복구 시 데이터의 정합성을 유지할 수 있도록 했습니다.  
> 결과적으로 운영 중단 없이 자동 복구가 가능해졌고, 재현 테스트도 안정적으로 통과할 수 있었습니다.  
{: .block-tip }  

## 데이터베이스 성능 이슈를 경험하고 이를 해결한 경험이 있다면 공유해주세요. 어떤 문제가 있었고, 어떤 방식으로 진단하고 개선했는지 설명해주세요.
> 카테고리: Backend, 데이터베이스 최적화 경험

> 힌트: 인덱스 최적화, 쿼리 튜닝, 데이터 모델링 개선, 캐싱 도입 등의 경험을 떠올려보세요. 성능 측정 방법과 개선 효과도 함께 설명하면 좋습니다.

### 답변 
사이드 프로젝트에서 콘서트 일정 조회 시 성능 이슈를 겪었습니다. concert_id 기준으로 약 150개 정도의 데이터만 조회되지만, 인덱스가 제대로 활용되지 않아 테이블 스캔이 발생했습니다.   
문제의 원인은 카디널리티가 낮아 인덱스 효용이 떨어졌기 때문이었습니다. 이를 해결하기 위해 조회 조건에 맞는 조합 인덱스를 재설계하고, 쿼리 실행 계획을 분석하며 최적화했습니다.    
k6를 이용해 성능 테스트한 결과 쿼리 비용과 실행 시간을 개선했습니다. 이 경험을 통해 단순히 인덱스를 추가하는 것보다 카디널리티와 실행 계획 분석이 더 중요하다는 점을 배웠습니다.  

> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> 토이 프로젝트에서 게시글 목록을 불러올 때 페이지 로딩이 느려지는 문제가 있었습니다. 개발 도구로 확인해보니 DB 쿼리 실행 시간이 길었고, EXPLAIN 명령어로 분석한 결과 인덱스가 제대로 활용되지 않고 있었습니다. 게시글 테이블에 복합 인덱스를 추가하고, 페이지네이션 쿼리를 최적화한 결과 조회 시간이 2초에서 0.3초로 단축되었습니다.  
>   
> [현직 개발자로, 이직 면접이라면?]  
> 실시간 대시보드 서비스에서 사용자가 늘어나면서 DB 부하가 증가하고 응답 시간이 10초 이상으로 늘어나는 문제가 발생했습니다. 프로파일링 결과, 자주 조회되는 통계 데이터를 매번 계산하는 것이 원인이었습니다. 이를 해결하기 위해 Redis를 도입해 계산된 결과를 캐싱하고, 배치 작업으로 주기적으로 갱신하는 방식으로 변경했습니다. 또한 자주 사용되는 쿼리에 적절한 인덱스를 추가하고, 일부 테이블은 파티셔닝을 적용했습니다. 결과적으로 평균 응답 시간이 0.5초 이내로 개선되었고, DB 서버 부하도 70% 감소했습니다.  
{: .block-tip }  


## 프로젝트에서 기술 부채를 어떻게 정의하고, 그것을 정량화하거나 체계적으로 관리해본 경험이 있다면 설명해주세요. 그 과정을 통해 어떤 효과가 있었는지도 함께 이야기해주세요.
> 카테고리: 공통, 기술 부채 관리

> 힌트: 기술 부채는 빠른 개발을 위해 나중에 갚기로 한 '빚' 같은 기술적 타협을 말하며, 코드 중복, 테스트 누락, 문서화 부족 등도 포함됩니다. 기술 부채에 대한 정량화 기준(예: PR backlog, 테스트 커버리지 등), 대응 방식(Refactor Sprint, 주간 점검 등)을 중심으로 답변해 보세요.

### 답변 
프로젝트 진행 중, 서비스 내 소프트웨어 간 의존성이 명확하지 않아 기능 별로 어떤 서비스가 필수인지, 선택적인지 파악하기 어려운 문제가 있었습니다. 저는 이를 기술 부채로 인식하고, 시스템 전반의 구성과 의존 관계를 시각화 하여 문서화 하는 작업을 수행했습니다.  
  
각 소프트웨어의 역할과 중요도를 정리하고, 필수 여부, 요청 흐름, 이미지 및 버전 정보 등을 포함한 도식화된 문서를 체계적으로 관리함으로써, 기술 부채를 줄이고 서비스 구조의 명확성을 높였습니다.  

> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> 팀 프로젝트에서 일정이 촉박해 공통 컴포넌트를 빠르게 하드코딩 방식으로 처리한 적이 있습니다.  
> 나중에는 같은 컴포넌트에 반복적으로 수정이 들어가면서 유지보수가 어려워졌고, 이걸 계기로 리팩토링 전용 스프린트를 따로 만들었습니다.  
> 기능과 속도만 보던 초반과 달리, 이후엔 기술 부채도 하나의 '관리 대상'으로 인식하게 되었고, 지금은 설계 단계에서부터 중복과 확장 가능성을 의식하려 노력하고 있습니다.  
>   
> [현직 개발자로, 이직 면접이라면?]  
> 사내 프로젝트에서 테스트 커버리지 부족, 중복 로직, 복잡한 조건문이 점점 쌓이면서 개발 속도도 떨어지고 버그 빈도가 높아졌습니다.  
> 이를 해결하기 위해 기술 부채 점검 기준을 팀 차원에서 정리하고, 매 스프린트마다 일정 비율로 리팩토링 태스크를 포함했습니다.  
{: .block-tip }  

## 기존 코드베이스에서 리팩토링을 진행한 경험이 있다면, 어떤 문제를 발견했고 어떻게 개선했는지 설명해주세요. 리팩토링 전후의 차이점과 그 결과도 함께 공유해주세요.
> 카테고리: 공통, 코드 리팩토링 경험

> 힌트: 리팩토링은 외부 동작을 바꾸지 않으면서 내부 구조를 개선하는 과정입니다. 코드 중복 제거, 함수 분리, 클래스 재구성 등의 경험을 떠올려보세요.

### 답변   
Elasticsearch에 저장된 이미지 메타데이터를 조회하는 API에서, 데이터 양이 많아지면서 로딩 시간이 점점 길어지는 문제가 발생했습니다.  
기존에는 from과 size를 이용한 오프셋 기반 페이지네이션 방식을 사용하고 있었는데, 이 방식은 데이터가 많아질수록 성능 저하가 발생하는 구조였습니다.  
  
이 문제를 해결하기 위해 search_after를 도입하여 페이지네이션 방식을 개선했습니다. search_after는 오프셋을 사용하지 않고, 특정 정렬 기준 이후의 데이터를 탐색하기 때문에 대용량 데이터 처리에 훨씬 효율적입니다.  
정렬 기준은 고유성과 정렬 안정성이 보장된 id 필드를 사용하여, 기존의 오프셋 기반 페이지네이션을 커서 기반 방식으로 전환했습니다.  
  
클라이언트 요청 형식은 기존과 동일하게 유지하면서, 내부적으로만 search_after 기반 구조로 변환하여 외부 API 인터페이스는 변경 없이 성능 개선을 이끌어낼 수 있었습니다.  


> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> 팀 프로젝트에서 API 호출 로직이 여러 컴포넌트에 중복되어 있어 유지보수가 어려웠습니다. 이를 개선하기 위해 공통 훅(custom hook)으로 분리하고, 에러 처리와 로딩 상태 관리도 일관되게 처리했습니다. 리팩토링 후에는 코드량이 30% 정도 줄었고, 새로운 API 연동 시 개발 시간도 크게 단축되었습니다.  
>   
> [현직 개발자로, 이직 면접이라면?]  
> 레거시 프로젝트에서 비즈니스 로직과 UI 로직이 혼재된 컴포넌트를 발견했습니다. 이로 인해 테스트가 어렵고 기능 확장 시 사이드 이펙트가 자주 발생했습니다. 이를 개선하기 위해 Presenter-Container 패턴을 적용해 비즈니스 로직을 분리하고, 단위 테스트를 추가했습니다. 결과적으로 테스트 커버리지가 40%에서 75%로 증가했고, 이후 기능 추가 시 버그 발생률이 60% 감소했습니다.  
{: .block-tip }  

## 팀 내에서 기술적 의견 차이가 있었던 상황에서, 본인의 입장을 유지하면서도 상대와 타협하거나 협상을 이끌어낸 경험이 있다면 공유해주세요.
> 카테고리: 인성, 의견 충돌과 협상

> 힌트: 기술 선택, 일정 조율, 코드 스타일, 구현 방식 등에서 갈등이 생길 수 있습니다. 여기서 포인트는 "무작정 고집"이 아니라, 근거 기반 설득 → 협상 → 합의 도출의 과정이며, 자신이 제안한 방식이 채택되지 않아도, 과정이 건강했다면 좋은 예입니다!

### 답변 
개발팀에서 인공지능 모델의 학습 및 추론 컨테이너 실행 시간만큼 마일리지를 차감하는 기능을 설계하던 중, 컨테이너 실행 시간을 측정하는 기준을 두고 의견 차이가 있었습니다.
일부 팀원은 Kubernetes API를 통해 서비스에서 컨테이너를 생성한 시점과 종료 시점을 기준으로 삼자고 했지만, 이 경우 컨테이너가 실제로 준비되기 전 시간까지 포함되어 정확한 사용 시간 측정에 오차가 생기는 문제가 있었습니다.  
  
저는 이러한 문제를 해결하기 위해 Kubernetes Audit 로그를 활용하자는 대안을 제시했습니다. Audit 로그를 통해 컨테이너 상태 변화와 정확한 시간 정보를 가져올 수 있으며, 이를 기반으로 하면 실제 사용 시간만 정확하게 추출할 수 있었습니다.  
  
팀원들과의 논의 끝에 제 의견이 받아들여졌고, 이를 기반으로 기능을 구현하여 요구사항에 부합하면서도 신뢰도 높은 시간 측정 로직을 완성할 수 있었습니다.   

> ##### 모범 답안
> [첫 취업 준비생이라면?]  
> 팀 프로젝트에서 UI 라이브러리를 통일할지 각자 사용하는 방식대로 진행할지를 두고 팀원과 의견이 엇갈렸습니다.  
> 저는 유지보수와 코드 통일성 측면에서 통일된 라이브러리가 낫다고 주장했고, 그 근거를 문서로 정리한 뒤 공유했습니다.  
> 결과적으로 토론 끝에 메인 기능은 통일된 라이브러리를 쓰되, 부가 기능은 자유롭게 구현하기로 타협점을 찾을 수 있었습니다.  
> 
> 
> [현직 개발자로, 이직 면접이라면?]  
> 코드 리뷰 중 유틸 함수의 책임 분리를 두고 팀원과 충돌이 있었습니다. 저는 단일 책임 원칙에 따라 분리를 제안했고, 팀원은 복잡성 증가를 우려했습니다.  
> 이에 기존 코드에서 발생했던 유지보수 이슈를 기반으로 설명하고, 일단 분리해 적용 후 회고에서 다시 검토하기로 했습니다.  
> 최종적으로는 설계의 장점이 입증되었고, 팀의 기술 토론 문화가 더 성숙해지는 계기가 되었습니다.  
{: .block-tip }  

---

<br>
<br>
<br>

# 2025.04.10  
## 마이크로서비스 혹은 분산 시스템에서 데이터 일관성을 유지하기 위한 전략을 고민하거나 적용한 경험이 있다면 공유해주세요. 규모가 작아도 서비스 간 데이터 처리 흐름을 설계해본 경험이면 충분합니다.
> 카테고리: Backend, 마이크로서비스 데이터 일관성

> 힌트: 단일 DB 트랜잭션이 아닌, 서비스 간 데이터 일관성을 유지하는 방식을 고민해본 경험을 떠올려 보세요. (예: Eventual Consistency, 이벤트 기반 처리, SAGA 패턴 등)

### 답변
사이드 프로젝트에서 좌석 예약 시스템을 개발한 경험이 있습니다.
예약이 완료되면 해당 정보를 데이터 플랫폼 시스템에서 활용할 수 있도록 이벤트를 발행하는 구조였고,
두 시스템은 각각 마이크로서비스 형태로 분리되어 있었습니다.

그런데 간혹 좌석 예약은 정상적으로 처리되었지만, 이벤트가 유실되거나 발행에 실패하는 문제가 발생했습니다.
이로 인해 실제 예약 정보가 데이터 플랫폼 쪽에 반영되지 않는 등, 서비스 간 데이터 정합성이 깨지는 이슈가 생길 수 있는 구조였습니다.

이를 해결하기 위해, 이벤트 발행 이후 동일 메시지를 내부 Kafka Consumer로 consume하여, 발행이 실제로 처리되었는지를 검증하는 구조를 도입했습니다.
이 과정에서 발행 실패 시 재발행을 시도하고, 일정 횟수 이상 실패할 경우에는 로그로 기록하고 수동 조치가 가능하도록 처리했습니다.

이 구조 덕분에 비동기 환경에서도 데이터 정합성을 어느 정도 보장할 수 있었고, 전체 시스템의 안정성도 향상되었습니다.
추후에는 DLQ(Dead Letter Queue)와 같은 메시지 유실 방지 장치를 도입하여 더욱 견고한 구조로 보완할 계획도 세웠습니다.

이 경험을 통해, 마이크로서비스 간 데이터 흐름에서는 보상 전략, 실패 검증, 장애 복구 수단까지 함께 고려해야 한다는 교훈을 얻을 수 있었습니다.

> ##### 모범 답안
> 
> [첫 취업 준비생이라면?]  
> 토이 프로젝트에서 사용자 서비스와 결제 서비스를 나누어 구현했는데, 결제 완료 후 사용자 상태를 업데이트하는 로직이 REST API 방식의 동기 호출되다 보니 결제 실패 시 사용자 상태가 잘못 변경되는 문제가 있었습니다. 이를 해결하기 위해 RabbitMQ를 도입해 결제 완료 시 이벤트 메시지를 발행하고, 사용자 서비스가 이를 구독해 상태를 변경하도록 했습니다. 비록 작은 프로젝트였지만, 서비스 간의 의존도를 줄이고 일관된 흐름을 유지하기 위해 비동기 메시징이 필요하다는 것을 체감할 수 있었습니다.
>   
> [현직 개발자로, 이직 면접이라면?]  
> 커머스 시스템에서 주문, 결제, 배송 서비스를 마이크로서비스로 분리한 이후, 주문 생성 후 결제 실패 시 데이터 정합성 이슈가 발생했습니다. 이를 해결하기 위해 SAGA 패턴을 기반으로 한 이벤트 드리븐 구조를 도입했고, Kafka를 이벤트 브로커로 사용해 서비스 간 데이터를 전달했습니다. 실패 시 보상 트랜잭션을 통해 이전 상태로 복구하는 로직을 각 서비스에 구현했으며, idempotent key 처리, DLQ 설계 등도 함께 적용해 안정성을 높였습니다. 결과적으로 연관 서비스 간 장애 전파율이 줄고 유지보수 ㄴ비용도 감소했습니다.
{: .block-tip }  

## 기존 코드베이스에 새로운 기술이나 도구를 도입했던 경험이 있다면, 어떤 리스크를 고려했고, 이를 어떻게 관리했는지 설명해주세요. 실무 경험이 없다면 팀 프로젝트나 사이드 프로젝트에서 고민했던 사례를 공유해 주세요.
> 카테고리: 공통, 기술 도입 시 리스크 관리

> 힌트: 도입 기술은 프레임워크, 상태 관리 도구, 빌드 시스템, 배포 도구 등 다양합니다. 기존 시스템과의 충돌, 학습 비용, 유지보수 리스크 등을 고려해 본 경험을 공유하세요.

### 답변  
Kubernetes 클러스터에 여러 기관의 플랫폼을 설치해야 했던 프로젝트에서, 
한 번에 다수의 플랫폼을 배포해야 했기 때문에 시간이 오래 걸리고 반복 작업도 많았습니다.  
  
당시에는 프로젝트 관리자나 운영팀이 직접 설치를 수행해야 하는 경우도 있었고, Helm 명령어 기반 배포 과정의 복잡성으로 인해 러닝 커브도 높은 상황이었습니다.  
  
이 문제를 해결하기 위해 '버튼 클릭만으로 배포 가능한 기능'을 목표로 설정했고, 
핵심 기술로 Helm Operator(Helm Controller)를 도입했습니다.  
Helm Operator는 Helm 차트를 Kubernetes 커스텀 리소스로 등록하고, 이를 자동으로 배포·관리할 수 있게 해주기 때문에, 기존 Helm 구조는 유지하면서도 자동화 수준을 높일 수 있는 장점이 있었습니다.    
   
기술 도입 당시 고려한 사항은 크게 3가지 였습니다.      
- 운영팀의 부담 최소화 하기위해 기존 Helm 배포 방식을 그대로 유지할 수 있는지 
- 새로운 컨트롤러 도입에 따른 리소스 관리 복잡도가 증가 하는지    
- 배포 실패 시 롤백 전략 및 오류 추적이 가능한지  
  
결과적으로 운영팀은 복잡한 설치 과정을 몰라도 UI에서 간단한 입력만으로 배포할 수 있게 되었고, 서비스 배포 시간도 단축되었습니다.  
  
이 경험을 통해, 새로운 기술 도입은 단순히 좋아 보여서 하는 것이 아닌, 기존 환경과 사용자 경험까지 함께 고민해야 한다는 것을 배웠습니다.   

> ##### 모범 답안
> 
> [첫 취업 준비생이라면?]  
> 졸업작품에서 Redux를 사용하던 기존 코드에 일부 기능만 Recoil로 바꿔보려 했던 적이 있습니다. 하지만 프로젝트 후반에 두 상태 관리 방식이 혼재되면서, 어떤 데이터가 어디서 변경되는지를 추적하기 어려워졌고, 디버깅 시간이 급증했습니다. 이를 해결하기 위해 팀원들과 함께 상태 관리 방식을 통일하기로 결정했고, Recoil로 전면 전환하되 이전 구조와의 차이점을 문서로 남겨 이후 팀원들이 적응할 수 있도록 했습니다. 이 경험을 통해 새로운 기술 도입은 기능 중심이 아니라 유지보수성과 팀 전체의 이해도까지 고려해야 한다는 교훈을 얻었습니다.
>   
> [현직 개발자로, 이직 면접이라면?]  
> 사내에서 오래된 Gulp 기반 빌드 환경을 유지하던 프로젝트가 있었습니다. 기능이 많아지면서 빌드 시간이 길어지고, 일부 플러그인은 유지보수가 어려워져 문제가 반복됐습니다. 이를 해결하기 위해 Webpack 기반 환경으로 점진적 전환을 제안했고, 기존 Gulp task를 하나씩 Webpack config로 이관하는 방식으로 진행했습니다. 특히 코드 분할(Code Splitting), HMR 도입 등으로 로컬 개발 빌드 시간이 평균 30% 단축되었고, 에러 추적도 쉬워졌습니다. 중요한 건 새 도구 자체보다, 기존 시스템과 충돌 없이 점진적으로 바꾸는 과정이었고, 이를 위해 팀 내 문서화와 주간 공유를 병행했습니다.
{: .block-tip }  

## 최근에 실패했던 경험이 있다면 솔직하게 공유해 주세요. 그 실패로부터 무엇을 배우고, 어떻게 성장했는지도 함께 이야기해 주세요. 결과가 좋지 않아도 괜찮습니다.
> 카테고리: 인성, 실패 경험과 교훈

> 힌트: "실패"는 결과가 안 좋았던 프로젝트, 일정 지연, 기술 선택 실패, 협업 문제 등 다양합니다. 이런 질문의 핵심은 실패 자체보다 그 이후의 성찰과 변화가 무엇이었는지 묻는 거예요!

### 답변   
컨테이너 환경에서 GPU를 사용할 수 있도록 NVIDIA Device Plugin을 사용하고 있었습니다. 기존에는 GPU 종류가 바뀌더라도 큰 문제가 없었기 때문에, 설치 파일을 간소화하고 해당 플러그인만 사용하는 방식으로 운영 중이었습니다.

그러나 새로운 A100 GPU 환경에서는 일정 시간이 지나면 컨테이너가 GPU를 인식하지 못하는 문제가 발생했습니다. 당시에는 서비스가 운영 중이었고, 사용자들이 모델 재학습을 시도할 때 GPU 인식 오류로 인해 지속적으로 문의가 들어왔습니다.

문제를 분석해보니, docker daemon-reload가 발생할 때마다 GPU 링크가 끊기는 현상이었고, 이전에 잘 동작했기 때문에 “이번에도 문제없을 것”이라는 안일한 판단으로 충분한 테스트 없이 동일한 방식으로 배포한 것이 원인이었습니다.

이후에는 NVIDIA GPU Operator를 도입하여, GPU 드라이버 및 관련 플러그인을 자동으로 설치하고 링크 상태를 지속적으로 확인하도록 구성했고, 해당 이슈는 재발하지 않았습니다.

이 경험을 통해 작은 환경 변화라고 하더라도 테스트를 철저히 해야 한다는 점을 크게 느꼈습니다. 이후로는 환경이 조금이라도 변경되면 꼭 세세하게 검증을 마친 후에 배포하는 습관을 갖게 되었습니다.

> ##### 모범 답안
> 
> [첫 취업 준비생이라면?]  
> 팀 프로젝트 중 더 완성도 높은 결과물을 만들고 싶다는 욕심에, 개발 도중 기획을 확장하다 보니 마감 기한을 지키지 못했습니다. 특히 복잡한 필터링 기능을 추가했는데, 예상보다 많은 시간과 버그가 발생했고 팀원들의 부담도 커졌습니다. 이 경험을 통해 '무엇을 얼마나 잘 구현할 것인가'도 중요하지만, MVP를 명확히 정의하고 우선순위를 조율하는 것이 프로젝트의 핵심이라는 걸 배웠습니다. 이후엔 모든 프로젝트에서 이 부분을 가장 먼저 체크하고 있습니다.
>   
> [현직 개발자로, 이직 면접이라면?]  
> 첫 이직 후, 전 직장에서 쓰지 않던 GraphQL을 사용하는 프로젝트에 투입되었는데, 생소한 도구와 도메인 때문에 문제를 스스로 해결하려다 기능 배포가 지연된 적이 있습니다. "적응 중인데 민폐를 끼치기 싫다"는 생각에 요청을 미뤘지만, 오히려 팀에 부담을 준 결과였죠. 이후 팀 리더와 회고를 진행했고, 그 뒤로는 작은 어려움도 빠르게 공유하고 온보딩 기술 공유 세션을 자발적으로 운영했습니다. 이 경험은 "성장 = 혼자 해결"이라는 고정관념을 깬 계기가 되었고, 지금은 신규 입사자들의 질문을 먼저 들어주는 입장이 되었습니다.
{: .block-tip }  

---

<br>
<br>
<br>

# 2025.04.09
## RESTful API를 설계할 때 고려해야 할 주요 원칙들에 대해 설명하고, 좋은 RESTful API의 예시를 들어주세요.
> 카테고리: Backend, RESTful API 설계 원칙  

> 힌트: 자원(Resource), 행위(Verb), 표현(Representation)의 개념을 고려해보세요.

### 답변
RESTful API는 자원을 URL로 표현하고, 행위는 HTTP 메서드(GET, POST, PUT, DELETE 등)로 구분하며, 자원의 상태는 JSON 같은 표현 형식으로 주고받는 구조입니다.  
이러한 구조를 위해서는 각 요청을 독립적으로 만들고, 일관된 방식으로 리소스를 처리하게 하여 무상태성과 일관된 인터페이스 원칙을 지켜야 하며, 자원 기반 구조(Resource-Oriented Architecture), HTTP 메서드를 통한 행위 표현(Method Semantics), 표현을 통한 상태 전달(Representation of Resource State) 을 고려해야 합니다.  

> ##### 모범 답안
> 
> RESTful API 설계의 주요 원칙은  
> 1) 자원 기반 구조(URI로 자원 표현),  
> 2) HTTP 메서드를 통한 행위 표현(GET, POST, PUT, DELETE),   
> 3) 무상태성(Stateless),   
> 4) 캐시 가능성,   
> 5) 계층화된 시스템,   
> 6) 통일된 인터페이스입니다.   
> 좋은 예시로는 GitHub API가 있으며, 자원을 명확히 표현하고 적절한 HTTP 메서드를 사용합니다.
{: .block-tip } 


## 동시성 문제란 무엇이며, 이를 해결하기 위한 기본적인 전략을 설명해주세요. 실제 운영 환경에 적용한 사례가 있다면 함께 설명해 주어도 좋습니다.
> 카테고리: Backend, 동시성 문제 해결  

> 힌트: 동시성은 다중 사용자/요청이 동시에 자원에 접근할 때 발생합니다. 락(lock), 큐(queue), 트랜잭션 격리 수준 등의 개념을 활용해 본 경험을 떠올려 보세요.

### 답변
동시성 문제란, 여러 개의 프로세스나 스레드가 동시에 하나의 공유 자원에 접근할 때, 예상치 못한 결과나 데이터 정합성 문제가 발생하는 현상을 말합니다. 예를 들어 동시에 같은 좌석을 예약하거나, 동일한 재고를 두 번 차감하는 상황이 이에 해당합니다.  
  
이러한 문제를 해결하기 위한 기본적인 전략으로는 락(Lock) 메커니즘, 트랜잭션 격리 수준 설정, 낙관적/비관적 락, 요청 큐잉 등이 있습니다. 락을 사용하면 한 시점에 하나의 쓰레드만 자원에 접근하도록 제한할 수 있으며, 큐는 요청을 순차적으로 처리해 동시에 발생하지 않도록 방지합니다.  
  
실제로 저는 좌석 예약 API를 개발하면서 동시성 문제를 해결한 경험이 있습니다. 특정 공연에 좌석 예약 요청이 동시에 몰리는 상황에서, 이중 예약을 방지하기 위해 Redis 기반의 분산 락(distributed lock)을 적용했습니다. Redis의 SETNX 명령어를 활용해 한 번에 하나의 사용자만 특정 좌석에 접근할 수 있도록 제어했고, 락의 유효 시간을 설정하여 데드락(deadlock)도 방지했습니다. 이를 통해 DB 부하도 줄이고, 안정적인 예약 처리를 할 수 있었습니다.  


> ##### 모범 답안
>
> [첫 취업 준비생이라면?]  
> 동시성 문제는 여러 사용자가 동시에 같은 자원에 접근할 때, 의도하지 않은 결과가 생기는 현상입니다. 예를 들어, 게시글 추천 수를 동시에 여러 명이 누르면 실제 추천 수보다 적거나 중복될 수 있습니다. 이를 해결하기 위해 DB에서 트랜잭션을 활용하거나, 어플리케이션 단에서는 락을 사용하는 방법을 학습했습니다. 개인 프로젝트에서 단순한 예시로 Python에서 threading을 사용한 카운터 처리에서 race condition을 실험하고 해결한 적이 있습니다.
> 
> [현직 개발자로, 이직 면접이라면?]  
> 실제 운영 중이던 커머스 서비스에서, 주문 수량 처리 중 동시성 이슈로 재고가 마이너스로 떨어지는 문제가 있었습니다. 해결을 위해 Redis를 활용한 분산 락 시스템(Redlock)을 도입했고, 동시에 트랜잭션의 격리 수준을 Read Committed → Repeatable Read로 조정했습니다. 이후에는 race condition 없이 재고 처리가 안정적으로 이루어졌고, 동시에 예약 처리가 필요한 기능에도 확장 적용할 수 있었습니다.
{: .block-tip }  

## 최근 5년간 발전한 기술 트렌드 중, 당신의 개발 방식 또는 학습 방식에 가장 큰 영향을 준 기술은 무엇인가요? 그 이유와, 실제로 적용해 보았거나 흥미롭게 느꼈던 경험이 있다면 함께 설명해 주세요.

> 카테고리: 공통, 최신 기술 트렌드의 영향

> 힌트: "기술 트렌드"는 AI, 클라우드, 프레임워크 변화, DevOps 도구 등 다양합니다. 학습 방식이나 개발 철학에 영향을 준 경험 중심으로 이야기해 보세요.

### 답변
최근 5년간 저에게 가장 큰 영향을 준 기술은 Kubernetes입니다. 클라우드 네이티브 환경이 표준화되면서, Kubernetes는 인프라 설계의 핵심 도구로 자리잡았고, 저는 이 과정에서 ‘기술을 구조적으로 이해하는 습관’을 갖게 되었습니다.

Kubernetes는 내부적으로 다양한 개념을 자체 용어와 방식으로 추상화해 제공하는데, 이 덕분에 새로운 기술을 학습할 때 기존 개념과 연결해 이해하거나, 제 방식대로 재구성하여 이해하는 학습 습관을 갖게 되었습니다.

실제로 온프레미스 환경에서 인프라를 구성할 때도, Kubernetes의 리소스 설계와 개념을 참조하여 방화벽, 로드밸런서, DNS 구성 등 다양한 요소를 클라우드 개념에 빗대어 정리할 수 있었고, 덕분에 팀원들과의 소통도 훨씬 원활했습니다.

이 경험을 통해 단순히 기술을 ‘쓸 줄 아는 것’을 넘어, 개념을 추상화하고 내 방식으로 이해하는 능력이 장기적으로 성장하는 데 큰 힘이 된다고 느꼈습니다.

> ##### 모범 답안
>
> [첫 취업 준비생이라면?]  
> 저는 최근 빠르게 발전하고 있는 AI 기반 개발 도구(GitHub Copilot)의 등장이 가장 인상 깊었습니다. 졸업 프로젝트를 진행하면서 처음 사용해 보았는데, 코드 자동완성을 넘어 테스트 함수나 반복 로직의 구조까지 제안해주는 점이 놀라웠습니다. 이 도구 덕분에 단순 구현보다 코드 구조와 설계에 더 집중하는 개발 습관을 기를 수 있었습니다. 실무에 들어가서도 이런 AI 보조 도구를 적극 활용하면 빠르게 성장할 수 있을 것 같다고 느꼈습니다.
> 
> [현직 개발자로, 이직 면접이라면?]  
> 가장 큰 영향을 준 기술은 CI/CD 자동화 환경과 GitHub Actions의 확산입니다. > 반복되는 배포 과정과 QA 자동화를 줄이기 위해 팀 내에서 직접 Actions 워크플로우를 구성하고 운영해본 경험이 있습니다. 특히 QA 테스트 결과에 따라 PR을 자동으로 머지/반려하도록 설정하면서 개발 효율성과 팀 신뢰도가 높아졌습니다. 이러한 경험은 코드 작성뿐만 아니라 팀 내 개발 프로세스 개선까지 주도하는 역량을 키우는 데 도움이 되었습니다.
{: .block-tip }  

## 프로젝트 진행 중 협업 과정에서 갈등이나 의견 차이가 있었던 경험이 있다면, 이를 어떻게 해결했는지 설명해주세요. 그 과정에서 본인이 맡았던 역할과 결과도 함께 알려주세요.

> 카테고리: 인성, 갈등 중재 경험

> 힌트: "갈등"은 코드 스타일, 일정 조율, 기술 선택 등 작은 것도 포함됩니다. 감정적 판단보다 협업과 결과 중심의 해결 노력을 강조해 보세요.

### 답변
프로젝트를 진행하면서, 개발팀이 인지한 기능 완료 범위와 PM이 기대하는 결과물 간에 차이가 있었던 적이 있습니다. 개발팀은 기능 구현이 완료됐다고 판단했지만, 일부 동작이나 UI 흐름에서 기대에 미치지 못하는 부분들이 남아 있었습니다.  
  
당시 저는 배포 담당이었지만, 전체 흐름을 잘 알고 있던 만큼 일정 여유를 활용해 UI 통합 테스트를 진행했습니다. 사용자 관점에서 플로우를 재점검하며, 누락되었거나 매끄럽지 않은 동작을 정리해 개발팀과 PM 양측에 공유했습니다. 이 과정에서 서로의 기준 차이를 조율할 수 있도록 중간자 역할을 수행했습니다.
  
결과적으로, QA 과정에서 발생할 수 있었던 이슈를 사전에 방지했고, 일정 지연 없이 데드라인 내 프로젝트를 성공적으로 마무리할 수 있었습니다. 이 경험을 통해 팀 간 기대치 조율과 사전 커뮤니케이션의 중요성을 실감하게 되었습니다. 

> ##### 모범 답안
>
> [첫 취업 준비생이라면?]  
> 팀 프로젝트 중 백엔드 API 명세를 문서화하는 방식을 두고 의견 차이가 있었습니다. > 어떤 팀원은 Notion, 저는 Swagger UI를 주장했죠. 갈등을 줄이기 위해 각 방식의 장단점을 정리해 공유하고, 실제 구현 테스트도 함께 해보자는 제안을 했습니다. > 결과적으로 Swagger가 자동화와 유지보수 측면에서 낫다는 데 모두 동의했고, 팀워크도 자연스럽게 회복되었습니다.
> 
> [현직 개발자로, 이직 면접이라면?]  
> 코드 리뷰 과정에서 주니어 개발자와 네이밍 규칙을 두고 의견이 충돌한 적이 있습니다. 단순히 지적하기보다, 그 규칙이 왜 필요한지 설명하고 예시를 제시했습니다. > 이후에는 리뷰 문화에 대한 가이드를 팀 내에 문서화했고, 리뷰 가이드 세션도 주도했습니다. 개인적인 의견 차이에서 시작된 갈등을 협업 문화 개선의 기회로 바꾼 경험이었습니다.
{: .block-tip }